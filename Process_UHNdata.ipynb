{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2842"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_diag=pd.read_excel(\"Processed_GODFATHER_DIAG.xlsx\")\n",
    "df_bw=pd.read_excel(\"Processed_bw_panel.xlsx\")\n",
    "df_isupp=pd.read_excel(\"Processed_GODFATHER_ISUPP.xlsx\")\n",
    "df_Oct=pd.read_excel('Processed_GODFATHEROct242019.xlsx')\n",
    "GODFATHER_Oct24_ID=df_Oct['SUBJ_ID'].unique().tolist()\n",
    "len(GODFATHER_Oct24_ID)\n",
    "\n",
    "len(df_isupp['SUBJ_ID'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract subject_id from GODFATHER_ISUPP and GODFATHER_DIAG:\n",
    "#dfisupp_ID list of subject ID but with_1:\n",
    "dfisupp_ID=df_isupp['SUBJ_ID'].unique().tolist()\n",
    "#df_diag_ID is the list of subject ID but with_1:\n",
    "df_diag_ID=df_diag['SUBJ_ID'].unique().tolist()\n",
    "\n",
    "our_list=[]\n",
    "i=0\n",
    "def extract1(target_list):\n",
    "    for i in range(0, len(target_list)):\n",
    "        target_list[i] = str(target_list[i])\n",
    "        our_list.append(target_list[i].split('_')[0] )\n",
    "    return our_list\n",
    "\n",
    "\n",
    "#Use GODFATHER_ISUPP_ID to compare with other datasets\n",
    "GODFATHER_ISUPP_ID=extract1(dfisupp_ID)\n",
    "GODFATHER_ISUPP_ID=list(GODFATHER_ISUPP_ID)\n",
    "for i in range(0, len(GODFATHER_ISUPP_ID)): \n",
    "    GODFATHER_ISUPP_ID[i] = int(GODFATHER_ISUPP_ID[i])  \n",
    "\n",
    "\n",
    "my_list=[]\n",
    "def extract2(desired_list):\n",
    "    for i in range(0, len(desired_list)):\n",
    "        desired_list[i] = str(desired_list[i])\n",
    "        my_list.append(desired_list[i].split('_')[0] )\n",
    "    return my_list\n",
    "\n",
    "#Use GODFATHER_DIAG_ID to compare with otherdatasets\n",
    "GODFATHER_DIAG_ID=extract2(df_diag_ID)\n",
    "GODFATHER_DIAG_ID=list(GODFATHER_DIAG_ID)\n",
    "for i in range(0, len(GODFATHER_DIAG_ID)): \n",
    "    GODFATHER_DIAG_ID[i] = int(GODFATHER_DIAG_ID[i])  \n",
    "\n",
    "GODFATHER_Oct24_ID=df_Oct['SUBJ_ID'].unique().tolist()\n",
    "bw_panel_ID=df_bw['SUBJECT_ID'].unique().tolist()\n",
    "\n",
    "#to find the common patient ID between 4 datasets: GODFATHER_Oct242019, GODFATHER_ISUPP, GODATHER_DIAG, bw_panel:\n",
    "#common_ID=set(GODFATHER_Oct24_ID) & set(bw_panel_ID) & set(GODFATHER_DIAG_ID)& set(GODFATHER_ISUPP_ID)\n",
    "\n",
    "#to find the common patients ID between 2 datasets GODFATHER_Oct242019, GODFATHER_ISUPP:\n",
    "target_common_ID=set(GODFATHER_Oct24_ID) & set(GODFATHER_ISUPP_ID)\n",
    "\n",
    "#len(df['SUBJ_ID'].unique().tolist())\n",
    "#print('The number of patients in original database Oct242019:',len(df['SUBJ_ID'].unique().tolist()))\n",
    "print('The number of patients in the processed GODFATHER_Oct2420:', len(df_Oct['SUBJ_ID'].unique().tolist()))\n",
    "print('The number of patients in the processed bw_panel:', len(bw_panel_ID))\n",
    "print('The number of patients in the GOD_FATHER_DIAG',len(GODFATHER_DIAG_ID))\n",
    "print('The number of patients in the GOD_FATHER_ISUPP',len(GODFATHER_ISUPP_ID))\n",
    "print('The number of common patients in all 4 datasets:',len(target_common_ID))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of infection patients in the datasets: 220\n",
      "The number of cancer patients in the datasets: 256\n",
      "The number of cardiac patients in the datasets: 132\n",
      "The number of graft failure patients in the datasets: 164\n",
      "The number of renal failure patients in the datasets: 15\n",
      "The number of survived patients in the datasets: 2054\n"
     ]
    }
   ],
   "source": [
    "#To include database for common patients found in GODFATHER_ISUPP and GODFATHER_Oct242019 for GODFATHER_Oct242019:\n",
    "oct24_frames = []\n",
    "i = 0\n",
    "for e in target_common_ID:\n",
    "    oct24_frames += [(df_Oct.loc[(df_Oct['SUBJ_ID'] == e)])] \n",
    "            \n",
    "Revised_GODFATHEROct242019 = pd.concat(oct24_frames)\n",
    "\n",
    "#to find the number of infection patients in GODFATHER_Oct242019:\n",
    "infection_1=Revised_GODFATHEROct242019.loc[Revised_GODFATHEROct242019['Death_infection'] == 1.0]\n",
    "print('The number of infection patients in the datasets:', len(infection_1['SUBJ_ID'].unique().tolist()))\n",
    "\n",
    "#to find the number of cancer patients in GODFATHER_Oct242019:\n",
    "cancer_1=Revised_GODFATHEROct242019.loc[Revised_GODFATHEROct242019['Death_malignancy'] == 1.0]\n",
    "print('The number of cancer patients in the datasets:', len(cancer_1['SUBJ_ID'].unique().tolist()))\n",
    "\n",
    "#to find the number of cardiac patients in GODFATHER_Oct242019:\n",
    "cardiac_1=Revised_GODFATHEROct242019.loc[Revised_GODFATHEROct242019['Death_Cardiovascular'] == 1.0]\n",
    "print('The number of cardiac patients in the datasets:', len(cardiac_1['SUBJ_ID'].unique().tolist()))\n",
    "\n",
    "#to find the number of graft_failure patients in GODFATHER_Oct242019:\n",
    "graft_failure_1=Revised_GODFATHEROct242019.loc[Revised_GODFATHEROct242019['Death_Graft_related'] == 1.0]\n",
    "print('The number of graft failure patients in the datasets:', len(graft_failure_1['SUBJ_ID'].unique().tolist()))\n",
    "\n",
    "#to find the number of renal_failure patients in GODFATHER_Oct242019:\n",
    "renal_failure_1=Revised_GODFATHEROct242019.loc[Revised_GODFATHEROct242019['Death_Others'] == 1.0]\n",
    "print('The number of renal failure patients in the datasets:', len(renal_failure_1['SUBJ_ID'].unique().tolist()))\n",
    "\n",
    "#to find the number of survived patients in the GODFATHER dataset:\n",
    "survived_1=Revised_GODFATHEROct242019.loc[Revised_GODFATHEROct242019['died'] == 0.0]\n",
    "print('The number of survived patients in the datasets:', len(survived_1['SUBJ_ID'].unique().tolist()))\n",
    "Revised_GODFATHEROct242019.to_excel(\"Revised_GODFATHEROct242019.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_frames = []\n",
    "i = 0\n",
    "for e in target_common_ID:\n",
    "    bw_frames += [(df_bw.loc[(df_bw['SUBJECT_ID'] == e)])] \n",
    "    \n",
    "Revised_bw_panel = pd.concat(bw_frames)\n",
    "print(len(Revised_bw_panel['SUBJECT_ID'].unique().tolist()))\n",
    "print('Out of 2841 patienta, bw_panel has 2839 patients in the dataset')\n",
    "Revised_bw_panel.to_excel(\"Revised_bw_panel.xlsx\")\n",
    "\n",
    "#process GODFATHER_ISUPP:\n",
    "E=set(GODFATHER_ISUPP_ID)-set(target_common_ID)\n",
    "df_isupp\n",
    "\n",
    "df_isupp.drop(df_isupp.loc[df_isupp['SUBJ_ID']=='3220_1'].index, inplace=True)\n",
    "df_isupp.to_excel(\"Revised_GODFATHER_ISUPP.xlsx\")\n",
    "\n",
    "target_common_ID=list(target_common_ID)\n",
    "#Process GODFATHER_DIAG \n",
    "for i in range(0, len(target_common_ID)): \n",
    "    target_common_ID[i] = int(target_common_ID[i])\n",
    "\n",
    "D_1=[]\n",
    "def function(ab):\n",
    "    for i in range(0, len(ab)):\n",
    "        ab[i] = str(ab[i])\n",
    "        D_1.append(ab[i]+'_1')\n",
    "    return D_1\n",
    "\n",
    "common_ID_1=function(target_common_ID)\n",
    "\n",
    "\n",
    "diag_frames = []\n",
    "i = 0\n",
    "for e in common_ID_1:\n",
    "    diag_frames += [(df_diag.loc[(df_diag['SUBJ_ID'] == e)])] \n",
    "    \n",
    "Revised_GODFATHER_DIAG = pd.concat(diag_frames)\n",
    "print('Out of 2841 patients, GOD_FATHER_DIAG has 2363 patients in the dataset')\n",
    "\n",
    "Revised_GODFATHER_DIAG.to_excel(\"Revised_GODFATHER_DIAG.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag=pd.read_excel(\"Revised_GODFATHER_DIAG.xlsx\")\n",
    "bw=pd.read_excel(\"Revised_bw_panel.xlsx\")\n",
    "isupp=pd.read_excel(\"Revised_GODFATHER_ISUPP.xlsx\")\n",
    "Oct=pd.read_excel('Revised_GODFATHEROct242019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data=pd.read_excel('Revised_GODFATHER_ISUPP(2).xlsx')\n",
    "#Process the data\n",
    "#data.loc[data['TACROLIMUS']=='Unable to ','TACROLIMUS']=np.NaN\n",
    "list_to_replace=['Unable to ','RUSC','not drawn','NOT DONE','not done ','Not ordere','ND','.','   ','TGH','notOrdered','pt declnd','Unable  N&','w','N/D','lost','-','PEND','pnd','NoSpecimen','noSpecimen','DNR','Not Done','no order','RUSC, &','inaccurate','cancelled','Not done ','RUSC,**','RUSC,','PND','added','Q3mth','Insufficie','>  normal&','above','N//A',' n/d','Pending','<  normal&','no sample','not done','nd','no result','  ','s N','not Done','MISSED','not dnoe','No Spec','not ordere','not d','not receiv','N/ordered','notordered','notfound','7ina']      \n",
    "for e in list_to_replace:\n",
    "    data['TACROLIMUS']=data['TACROLIMUS'].replace(e, np.NaN)\n",
    "\n",
    "for e in data['TACROLIMUS'].unique().tolist(): \n",
    "    e=str(e)\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('(')[0] \n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('N')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('inacc')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('c')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('&')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('*')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('p')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('-')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('s')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('v')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('normal')[0]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('?')[1]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('only')[0]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('>')[1]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('<')[1]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('L')[1]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('+')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('i')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('trough')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('u')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('n')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('m')[0]\n",
    "\n",
    "#for e in trial['TACROLIMUS'].unique().tolist(): \n",
    "    #e=str(e)\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('?')[1]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('>')[1]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('<')[1]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('L')[1]\n",
    "\n",
    "for e in data['TACROLIMUS'].unique().tolist(): \n",
    "    e=str(e)\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('(')[0] \n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('N')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('inacc')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('c')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('&')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('*')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('p')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('-')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('s')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('v')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('normal')[0]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('?')[1]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('only')[0]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('>')[1]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('<')[1]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('L')[1]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('+')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('i')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('trough')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('u')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('n')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('m')[0]\n",
    "\n",
    "#trial.loc[(trial['TACROLIMUS'] == '5.7s ','TACROLIMUS')]='5.7s '.split('s')[0]\n",
    "#trial.loc[(trial['SUBJ_ID'] == '1040_1') &(trial['DAYS_POST_TX'] == 499)]\n",
    "for e in data['TACROLIMUS'].unique().tolist():\n",
    "    e=str(e)\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('c')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('?')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('f')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('LD2h.')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('I')[0]\n",
    "    data.loc[(data['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('*')[0]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('?')[1]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('>')[1]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('<')[1]\n",
    "    #trial.loc[(trial['TACROLIMUS'] == e,'TACROLIMUS')]=e.split('L')[1]\n",
    "    \n",
    "#trial.loc[(trial['TACROLIMUS'] == '<1.5','TACROLIMUS')]='<1.5'.split('<')[1]\n",
    "\n",
    "data['TACROLIMUS']=data['TACROLIMUS'].replace('11..0', '11.0')\n",
    "data['TACROLIMUS']=data['TACROLIMUS'].replace('2/0', '2.0')\n",
    "#to replace with null values:\n",
    "null_columns=['d/','o','. ','in','Took ','no s','.','Un ','do','ADDED','1hr','`',' ']\n",
    "for e in null_columns:\n",
    "    data['TACROLIMUS']=data['TACROLIMUS'].replace(e, np.NaN)\n",
    "\n",
    "#for e in data['TACROLIMUS'].unique().tolist():\n",
    "   # data.loc[(data['TACROLIMUS'] == e),'TACROLIMUS']=float(e)\n",
    "\n",
    "for i in range (len(data['TACROLIMUS'])):\n",
    "    data['TACROLIMUS'][i]=float(data['TACROLIMUS'][i])\n",
    "\n",
    "import numpy as np\n",
    "replace=['not done ','Test referr','n/d','ND','nd','not done','not ordered','Not Done','na','pnding','not drawn','pending','added','no labs','NOT DONE','notordered','not drwan','missed ','N/D','Not done','not ordere','no report','Unable to p','no sample','missed n/d','N/Ordered','n.a','-','pnd','Insufficien',' ','n,a','.','']\n",
    "for e in replace:\n",
    "    data['SIRO_LEVEL']=data['SIRO_LEVEL'].replace(e, np.NaN)\n",
    "\n",
    "for e in data['SIRO_LEVEL'].unique().tolist(): \n",
    "    e=str(e)\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('&')[0] \n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('v')[0]\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('(')[0]\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('*')[0]\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('c')[0]\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('W')[0]\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.splfdcrxe3it('s')[0]\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('HI')[0]\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('N')[0]\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('ng/ml')[0]\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('error')[0]\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('ug/L')[0]\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('A')[0]\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('ina')[0]\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split('s')[0]\n",
    "    \n",
    "data['SIRO_LEVEL']=data['SIRO_LEVEL'].replace('120/70', '1.71') \n",
    "\n",
    "\n",
    "for e in data['SIRO_LEVEL'].unique().tolist():\n",
    "    e=str(e)\n",
    "    data.loc[(data['SIRO_LEVEL'] == e,'SIRO_LEVEL')]=e.split(' ')[0]\n",
    "\n",
    "for i in range (len(data['SIRO_LEVEL'])):\n",
    "    data['SIRO_LEVEL'][i]=float(data['SIRO_LEVEL'][i])\n",
    "\n",
    "\n",
    " for e in data['SUBJ_ID'].unique().tolist(): \n",
    "    e=str(e)\n",
    "    data.loc[(data['SUBJ_ID'] == e,'SUBJ_ID')]=e.split('_')[0]\n",
    "\n",
    "for e in data['M_CYC'].unique().tolist(): \n",
    "    e=str(e)\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('&')[0] \n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('notc2')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split(' ')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('*')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('c')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('N')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('s')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('inaccur')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('STI')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('v')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('(')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('trough')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('ina')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('m')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('BID')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('`')[0]\n",
    "    data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('`')[0] \n",
    "    \n",
    "m_cyc_replace=['  ','not drawn','120/80','cant','132/199','-','.3','133/118','notordered','no','C4','n','','not','.']\n",
    "for e in m_cyc_replace:\n",
    "    data['M_CYC']=data['M_CYC'].replace(e, np.NaN)\n",
    "    \n",
    "for i in range (len(data['M_CYC'])):\n",
    "    data['M_CYC'][i]=float(data['M_CYC'][i]) \n",
    "\n",
    "#for e in data['M_CYC'].unique().tolist(): \n",
    "    #e=str(e)\n",
    "    #data.loc[(data['M_CYC'] == e,'M_CYC')]=e.split('`')[0]  \n",
    "\n",
    "for e in data['CYC_C3'].unique().tolist(): \n",
    "    e=str(e)\n",
    "    data.loc[(data['CYC_C3'] == e,'CYC_C3')]=e.split('N')[0] \n",
    "    \n",
    "for i in range (len(data['CYC_C3'])):\n",
    "    data['CYC_C3'][i]=float(data['CYC_C3'][i])\n",
    "    \n",
    "for e in data['CYC_C4'].unique().tolist(): \n",
    "    e=str(e)\n",
    "    data.loc[(data['CYC_C4'] == e,'CYC_C4')]=e.split('N')[0] \n",
    "    data.loc[(data['CYC_C4'] == e,'CYC_C4')]=e.split('s')[0] \n",
    "    data.loc[(data['CYC_C4'] == e,'CYC_C4')]=e.split(' ')[0]\n",
    "    \n",
    "    \n",
    "for i in range (len(data['CYC_C4'])):\n",
    "    data['CYC_C4'][i]=float(data['CYC_C4'][i])\n",
    "\n",
    "data['M_CYC'] = data['M_CYC'].astype(float)\n",
    "data['SIRO_LEVEL'] = data['SIRO_LEVEL'].astype(float)\n",
    "data['CYC_C3'] = data['CYC_C3'].astype(float)\n",
    "data['CYC_C4'] = data['CYC_C4'].astype(float)\n",
    "\n",
    "for e in data['CYC_C4'].unique().tolist(): \n",
    "    e=str(e)\n",
    "    data.loc[(data['CYC_C4'] == e,'CYC_C4')]=e.split('N')[0] \n",
    "    data.loc[(data['CYC_C4'] == e,'CYC_C4')]=e.split('s')[0] \n",
    "    data.loc[(data['CYC_C4'] == e,'CYC_C4')]=e.split(' ')[0]\n",
    "    \n",
    "    \n",
    "for i in range (len(data['CYC_C4'])):\n",
    "    data['CYC_C4'][i]=float(data['CYC_C4'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('UHN_immuno.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fol_immuno=pd.read_excel('UHN_immuno.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sophie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Sophie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Sophie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Sophie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Sophie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Sophie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Sophie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#To find out patient with immuno within the first 3 months:\n",
    "A=fol_immuno.loc[(fol_immuno['DAYS_POST_TX']<91)&(fol_immuno['DAYS_POST_TX']>60)]\n",
    "#len(A.groupby(['SUBJ_ID']).max()['DAYS_POST_TX'].tolist())\n",
    "three_months_idx = A.groupby(['SUBJ_ID'])['DAYS_POST_TX'].transform(max) == A['DAYS_POST_TX']\n",
    "three_months_database=A[three_months_idx]\n",
    "\n",
    "for e in three_months_database['DAYS_POST_TX'].unique().tolist():\n",
    "    three_months_database['DAYS_POST_TX']=three_months_database['DAYS_POST_TX'].replace(e, '3_months')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#To find out patient with immuno within the first 6 months:\n",
    "B=fol_immuno.loc[(fol_immuno['DAYS_POST_TX']<181)&(fol_immuno['DAYS_POST_TX']>90)]\n",
    "#len(A.groupby(['SUBJ_ID']).max()['DAYS_POST_TX'].tolist())\n",
    "six_months_idx = B.groupby(['SUBJ_ID'])['DAYS_POST_TX'].transform(max) == B['DAYS_POST_TX']\n",
    "six_months_database=B[six_months_idx]\n",
    "\n",
    "for e in six_months_database['DAYS_POST_TX'].unique().tolist():\n",
    "    six_months_database['DAYS_POST_TX']=six_months_database['DAYS_POST_TX'].replace(e, '6_months')\n",
    "    \n",
    "    \n",
    "    \n",
    "#To find out patients with immuno within the first 9 months:\n",
    "C=fol_immuno.loc[(fol_immuno['DAYS_POST_TX']<271)&(fol_immuno['DAYS_POST_TX']>180)]\n",
    "#len(A.groupby(['SUBJ_ID']).max()['DAYS_POST_TX'].tolist())\n",
    "nine_months_idx = C.groupby(['SUBJ_ID'])['DAYS_POST_TX'].transform(max) == C['DAYS_POST_TX']\n",
    "nine_months_database=C[nine_months_idx]\n",
    "\n",
    "for e in nine_months_database['DAYS_POST_TX'].unique().tolist():\n",
    "    nine_months_database['DAYS_POST_TX']=nine_months_database['DAYS_POST_TX'].replace(e, '9_months')\n",
    "\n",
    "    \n",
    "    \n",
    "#To find out patients with immuno for 1 year:\n",
    "D=fol_immuno.loc[(fol_immuno['DAYS_POST_TX']<366)&(fol_immuno['DAYS_POST_TX']>270)]\n",
    "#len(A.groupby(['SUBJ_ID']).max()['DAYS_POST_TX'].tolist())\n",
    "\n",
    "one_year_idx = D.groupby(['SUBJ_ID'])['DAYS_POST_TX'].transform(max) == D['DAYS_POST_TX']\n",
    "one_year_database=D[one_year_idx]\n",
    "\n",
    "for e in one_year_database['DAYS_POST_TX'].unique().tolist():\n",
    "    one_year_database['DAYS_POST_TX']=one_year_database['DAYS_POST_TX'].replace(e, 'one_year')\n",
    "    \n",
    "\n",
    "#to find out patients whom received immuno after the very first year- these patients do not have info before first year:\n",
    "min_idx = fol_immuno.groupby(['SUBJ_ID'])['DAYS_POST_TX'].transform(min) == fol_immuno['DAYS_POST_TX']\n",
    "min_data=fol_immuno[min_idx]\n",
    "\n",
    "after_1year=min_data.loc[(min_data['DAYS_POST_TX']>365)]\n",
    "\n",
    "for e in after_1year['DAYS_POST_TX'].unique().tolist():\n",
    "    after_1year['DAYS_POST_TX']=after_1year['DAYS_POST_TX'].replace(e, 'after_1year')\n",
    "\n",
    "#Last follow up for each patient:\n",
    "last_followup_idx = fol_immuno.groupby(['SUBJ_ID'])['DAYS_POST_TX'].transform(max) == fol_immuno['DAYS_POST_TX']\n",
    "last_followup_data=fol_immuno[last_followup_idx]\n",
    "\n",
    "for e in last_followup_data['DAYS_POST_TX'].unique().tolist():\n",
    "    last_followup_data['DAYS_POST_TX']=last_followup_data['DAYS_POST_TX'].replace(e, 'last_follow_up')\n",
    "\n",
    "    \n",
    "#First day for each patient for each patient:\n",
    "E=fol_immuno.loc[(fol_immuno['DAYS_POST_TX']<10)]\n",
    "\n",
    "first_day_idx = E.groupby(['SUBJ_ID'])['DAYS_POST_TX'].transform(min) == E['DAYS_POST_TX']\n",
    "first_day_database=E[first_day_idx]\n",
    "\n",
    "for e in first_day_database['DAYS_POST_TX'].unique().tolist():\n",
    "    first_day_database['DAYS_POST_TX']=first_day_database['DAYS_POST_TX'].replace(e, 'first_day')\n",
    "    \n",
    "    \n",
    "#Concatenate those values together\"\n",
    "frames = [first_day_database, three_months_database, six_months_database, nine_months_database,one_year_database,after_1year,last_followup_data]\n",
    "\n",
    "result = pd.concat(frames)\n",
    "\n",
    "result=result.sort_values(by=['SUBJ_ID'])\n",
    "\n",
    "result=result.drop(['CYC_C3', 'CYC_C4'], axis=1)\n",
    "\n",
    "result=pd.pivot_table(result,index=['SUBJ_ID'],columns=['DAYS_POST_TX'])\n",
    "\n",
    "result=result.drop(['CYC_C3', 'CYC_C4'], axis=1)\n",
    "one_record=pd.read_excel('Processed_GODFATHEROct242019.xlsx')\n",
    "fol_immuno=pd.read_excel('FOL_IMMUNO.xlsx')\n",
    "combined=one_record.set_index('TRR_ID').join(fol_immuno.set_index('SUBJ_ID'))\n",
    "combined.to_excel('Combined_data.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=data.sort_values(by=['SUBJ_ID','DIAG_DESC'])\n",
    "import pandas as pd\n",
    "data=pd.read_excel('UHN_DIAG.xlsx')\n",
    "\n",
    "data['DIAG_DESC'].unique()\n",
    "desired_list=['Sepsis', 'Pneumonia', 'C. Difficile', 'Cholangitis', 'CMV','UTI','Rejection']\n",
    "\n",
    "other_variables=[e for e in data['DIAG_DESC'].unique().tolist() if e not in desired_list]\n",
    "\n",
    "len(other_variables)\n",
    "\n",
    "\n",
    "for e in desired_list:\n",
    "    data.loc[(data['DIAG_DESC']==e,'Chronic_Disease')]='No'\n",
    "\n",
    "    \n",
    "for e in other_variables:\n",
    "    data.loc[(data['DIAG_DESC']==e,'Chronic_Disease')]='Yes'\n",
    "    \n",
    "    \n",
    "data.to_excel('DiaG.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other variables:\n",
    "#'Osteoporosis/penia'_database\n",
    "Osteoporosispenia= data.loc[(data['DIAG_DESC']=='Osteoporosis/penia')]\n",
    "Osteoporosispenia_idx = Osteoporosispenia.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Osteoporosispenia['Days_to_Diag']\n",
    "Osteoporosispenia_database=Osteoporosispenia[Osteoporosispenia_idx]\n",
    "\n",
    "#'Denovo_Malignancy'_database\n",
    "Denovo_Malignancy= data.loc[(data['DIAG_DESC']=='Denovo Malignancy')]\n",
    "Denovo_Malignancy_idx = Denovo_Malignancy.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Denovo_Malignancy['Days_to_Diag']\n",
    "Denovo_Malignancy_database=Denovo_Malignancy[Denovo_Malignancy_idx]\n",
    "\n",
    "\n",
    "#'Renal dysfunction'_database\n",
    "Renal_dysfunction= data.loc[(data['DIAG_DESC']=='Renal dysfunction')]\n",
    "Renal_dysfunction_idx = Renal_dysfunction.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Renal_dysfunction['Days_to_Diag']\n",
    "Renal_dysfunction_database=Renal_dysfunction[Renal_dysfunction_idx]\n",
    "\n",
    "\n",
    "#'Liver Fibrosis'_database\n",
    "Liver_Fibrosis= data.loc[(data['DIAG_DESC']=='Liver Fibrosis')]\n",
    "Liver_Fibrosis_idx = Liver_Fibrosis.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Liver_Fibrosis['Days_to_Diag']\n",
    "Liver_Fibrosis_database=Liver_Fibrosis[Liver_Fibrosis_idx]\n",
    "\n",
    "\n",
    "#'Smoking'_database\n",
    "Smoking= data.loc[(data['DIAG_DESC']=='History of Smoking')]\n",
    "Smoking_idx = Smoking.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Smoking['Days_to_Diag']\n",
    "Smoking_database=Smoking[Smoking_idx]\n",
    "\n",
    "\n",
    "#'Esophageal Varices'_database\n",
    "Esophageal_Varices= data.loc[(data['DIAG_DESC']=='Esophageal Varices')]\n",
    "Esophageal_Varices_idx = Esophageal_Varices.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Esophageal_Varices['Days_to_Diag']\n",
    "Esophageal_Varices_database=Esophageal_Varices[Esophageal_Varices_idx]\n",
    "\n",
    "\n",
    "#'Recurrent HCC'_database\n",
    "HCC= data.loc[(data['DIAG_DESC']=='Recurrent HCC')]\n",
    "HCC_idx = HCC.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == HCC['Days_to_Diag']\n",
    "HCC_database=HCC[HCC_idx]\n",
    "\n",
    "\n",
    "#'Pleural Effusion'_database\n",
    "Pleural_Effusion= data.loc[(data['DIAG_DESC']=='Pleural Effusion')]\n",
    "Pleural_Effusion_idx = Pleural_Effusion.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Pleural_Effusion['Days_to_Diag']\n",
    "Pleural_Effusion_database=Pleural_Effusion[Pleural_Effusion_idx]\n",
    "\n",
    "\n",
    "\n",
    "#'Atrial'_database\n",
    "Atrial= data.loc[(data['DIAG_DESC']=='Atrial Fibrillation')]\n",
    "Atrial_idx = Atrial.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Atrial['Days_to_Diag']\n",
    "Atrial_database=Atrial[Atrial_idx]\n",
    "\n",
    "\n",
    "\n",
    "#'Ascites'_database\n",
    "Ascites= data.loc[(data['DIAG_DESC']=='Ascites')]\n",
    "Ascites_idx = Ascites.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Ascites['Days_to_Diag']\n",
    "Ascites_database=Ascites[Ascites_idx]\n",
    "\n",
    "\n",
    "#'Diabetes'_database\n",
    "Diabetes= data.loc[(data['DIAG_DESC']=='Diabetes')]\n",
    "Diabetes_idx = Diabetes.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Diabetes['Days_to_Diag']\n",
    "Diabetes_database=Diabetes[Diabetes_idx]\n",
    "\n",
    "\n",
    "#'Systematic Hypertension'_database\n",
    "Hypertension= data.loc[(data['DIAG_DESC']=='Systematic Hypertension')]\n",
    "Hypertension_idx = Hypertension.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Hypertension['Days_to_Diag']\n",
    "Hypertension_database=Hypertension[Hypertension_idx]\n",
    "\n",
    "\n",
    "#'graft cirrhosis'_database\n",
    "cirrhosis= data.loc[(data['DIAG_DESC']=='graft cirrhosis')]\n",
    "cirrhosis_idx = cirrhosis.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == cirrhosis['Days_to_Diag']\n",
    "cirrhosis_database=cirrhosis[cirrhosis_idx]\n",
    "\n",
    "\n",
    "\n",
    "#'PTC drain issue'_database\n",
    "PTC= data.loc[(data['DIAG_DESC']=='PTC drain issue')]\n",
    "PTC_idx = PTC.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == PTC['Days_to_Diag']\n",
    "PTC_database=PTC[PTC_idx]\n",
    "\n",
    "\n",
    "\n",
    "#'Shingles'_database\n",
    "Shingles= data.loc[(data['DIAG_DESC']=='Shingles')]\n",
    "Shingles_idx = Shingles.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Shingles['Days_to_Diag']\n",
    "Shingles_database=Shingles[Shingles_idx]\n",
    "\n",
    "\n",
    "\n",
    "#'NAFLD'_database\n",
    "NAFLD= data.loc[(data['DIAG_DESC']=='NAFLD')]\n",
    "NAFLD_idx = NAFLD.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == NAFLD['Days_to_Diag']\n",
    "NAFLD_database=NAFLD[NAFLD_idx]\n",
    "\n",
    "\n",
    "\n",
    "#'Overweight'_database\n",
    "Overweight= data.loc[(data['DIAG_DESC']=='Overweight')]\n",
    "Overweight_idx = Overweight.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Overweight['Days_to_Diag']\n",
    "Overweight_database=Overweight[Overweight_idx]\n",
    "\n",
    "\n",
    "#'Billiary Duct Issues'_database\n",
    "Duct= data.loc[(data['DIAG_DESC']=='Billiary Duct Issues')]\n",
    "Duct_idx = Duct.groupby(['SUBJ_ID'])['Days_to_Diag'].transform(min) == Duct['Days_to_Diag']\n",
    "Duct_database=Duct[Duct_idx]\n",
    "\n",
    "#Sepsis:\n",
    "desired_list=['Sepsis', 'Pneumonia', 'C. Difficile', 'Cholangitis', 'CMV','UTI','Rejection']\n",
    "\n",
    "\n",
    "#Sepsis data is the patients diagnosed with Sepsis\n",
    "#Sepsis entered twice is the database where sepsis is diagnosed 2 time:\n",
    "Sepsis=data.loc[(data['DIAG_DESC']=='Sepsis')]\n",
    "Sepsis_counts=Sepsis['SUBJ_ID'].value_counts()\n",
    "Sepsis_entered_2=Sepsis[Sepsis['SUBJ_ID'].isin(Sepsis_counts.index[(Sepsis_counts > 1) &(Sepsis_counts < 3)])]    \n",
    "\n",
    "#To calculate for each patient if the previous row is larger than current row more than 30 days for sepsis 2:\n",
    "Sepsis_entered_2['Change']=Sepsis_entered_2.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "for e in (Sepsis_entered_2.loc[(Sepsis_entered_2['Change']< 31)])['SUBJ_ID'].unique().tolist():\n",
    "    Sepsis_entered_2.drop(Sepsis_entered_2.loc[(Sepsis_entered_2['SUBJ_ID']==e)&(Sepsis_entered_2['Change'].isnull())].index, inplace=True)\n",
    "\n",
    "    \n",
    "#Sepsis entered 3 is the database where sepsis is diagnosed 3 time:\n",
    "Sepsis_entered_3=Sepsis[Sepsis['SUBJ_ID'].isin(Sepsis_counts.index[(Sepsis_counts > 2) &(Sepsis_counts < 4)])]    \n",
    "\n",
    "Sepsis_entered_3['Change']=Sepsis_entered_3.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "\n",
    "Sepsis_entered_3.drop(Sepsis_entered_3.loc[(Sepsis_entered_3['SUBJ_ID']=='1218')&(Sepsis_entered_3['Days_to_Diag']==4896)].index, inplace=True)\n",
    "Sepsis_entered_3.drop(Sepsis_entered_3.loc[(Sepsis_entered_3['SUBJ_ID']=='1365')&(Sepsis_entered_3['Days_to_Diag']==10)].index, inplace=True)\n",
    "Sepsis_entered_3.drop(Sepsis_entered_3.loc[(Sepsis_entered_3['SUBJ_ID']=='1487')&(Sepsis_entered_3['Days_to_Diag']==22)].index, inplace=True)\n",
    "Sepsis_entered_3.drop(Sepsis_entered_3.loc[(Sepsis_entered_3['SUBJ_ID']=='2511')&(Sepsis_entered_3['Change']==42.0)].index, inplace=True)\n",
    "\n",
    "\n",
    "#Sepsis entered 4 is the database where sepsis is diagnosed 4 time:\n",
    "Sepsis_entered_4=Sepsis[Sepsis['SUBJ_ID'].isin(Sepsis_counts.index[(Sepsis_counts > 3)])]    \n",
    "Sepsis_entered_4['Change']=Sepsis_entered_4.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "\n",
    "Sepsis_entered_4.drop(Sepsis_entered_4.loc[(Sepsis_entered_4['SUBJ_ID']=='396')&(Sepsis_entered_4['Days_to_Diag']==5531)].index, inplace=True)\n",
    "Sepsis_entered_4.drop(Sepsis_entered_4.loc[(Sepsis_entered_4['SUBJ_ID']=='2973')&(Sepsis_entered_4['Change']==67.0)].index, inplace=True)\n",
    "Sepsis_entered_4.drop(Sepsis_entered_4.loc[(Sepsis_entered_4['SUBJ_ID']=='2973')&(Sepsis_entered_4['Days_to_Diag']==395.0)].index, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#Sepsis entered 1 is the database where sepsis is diagnosed 1 time:\n",
    "Sepsis_entered_1=Sepsis[Sepsis['SUBJ_ID'].isin(Sepsis_counts.index[(Sepsis_counts < 2)])]    \n",
    "\n",
    "\n",
    "sepsis_frames = [Sepsis_entered_1, Sepsis_entered_2, Sepsis_entered_3, Sepsis_entered_4]\n",
    "sepsis_database = pd.concat(sepsis_frames)\n",
    "\n",
    "#Pneumonia data is the patients diagnosed with Pneumonia\n",
    "#Pneumonia entered twice is the database where Pneumonia is diagnosed 2 time:\n",
    "Pneumonia=data.loc[(data['DIAG_DESC']=='Pneumonia')]\n",
    "Pneumonia_counts=Pneumonia['SUBJ_ID'].value_counts()\n",
    "\n",
    "Pneumonia_entered_2=Pneumonia[Pneumonia['SUBJ_ID'].isin(Pneumonia_counts.index[(Pneumonia_counts ==2)])]    \n",
    "\n",
    "Pneumonia_entered_2['Change']=Pneumonia_entered_2.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "Pneumonia_entered_2\n",
    "for e in (Pneumonia_entered_2.loc[(Pneumonia_entered_2['Change']< 31)])['SUBJ_ID'].unique().tolist():\n",
    "    Pneumonia_entered_2.drop(Pneumonia_entered_2.loc[(Pneumonia_entered_2['SUBJ_ID']==e)&(Pneumonia_entered_2['Change'].isnull())].index, inplace=True)\n",
    "\n",
    "\n",
    "#Pneumonia entered three is the database where Pneumonia is diagnosed 3 time:\n",
    "Pneumonia_entered_3=Pneumonia[Pneumonia['SUBJ_ID'].isin(Pneumonia_counts.index[(Pneumonia_counts >2)])]    \n",
    "Pneumonia_entered_3['Change']=Pneumonia_entered_3.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "\n",
    "Pneumonia_entered_3.drop(Pneumonia_entered_3.loc[(Pneumonia_entered_3['SUBJ_ID']=='589')&(Pneumonia_entered_3['Days_to_Diag']==638)].index, inplace=True)\n",
    "Pneumonia_entered_3.drop(Pneumonia_entered_3.loc[(Pneumonia_entered_3['SUBJ_ID']=='1030')&(Pneumonia_entered_3['Days_to_Diag']==91)].index, inplace=True)\n",
    "Pneumonia_entered_3.drop(Pneumonia_entered_3.loc[(Pneumonia_entered_3['SUBJ_ID']=='1050')&(Pneumonia_entered_3['Days_to_Diag']==14)].index, inplace=True)\n",
    "Pneumonia_entered_3.drop(Pneumonia_entered_3.loc[(Pneumonia_entered_3['SUBJ_ID']=='1129')&(Pneumonia_entered_3['Days_to_Diag']==45)].index, inplace=True)\n",
    "Pneumonia_entered_3.drop(Pneumonia_entered_3.loc[(Pneumonia_entered_3['SUBJ_ID']=='1129')&(Pneumonia_entered_3['Days_to_Diag']==31)].index, inplace=True)\n",
    "Pneumonia_entered_3.drop(Pneumonia_entered_3.loc[(Pneumonia_entered_3['SUBJ_ID']=='1232')&(Pneumonia_entered_3['Days_to_Diag']==7)].index, inplace=True)\n",
    "Pneumonia_entered_3.drop(Pneumonia_entered_3.loc[(Pneumonia_entered_3['SUBJ_ID']=='3444')&(Pneumonia_entered_3['Change']==0)].index, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#Pneumonia entered three is the database where Pneumonia is diagnosed 3 time:\n",
    "Pneumonia_entered_1=Pneumonia[Pneumonia['SUBJ_ID'].isin(Pneumonia_counts.index[(Pneumonia_counts==1)])]    \n",
    "\n",
    "Pneumonia_frames = [Pneumonia_entered_1, Pneumonia_entered_2, Pneumonia_entered_3]\n",
    "Pneumonia_database = pd.concat(Pneumonia_frames)\n",
    "\n",
    "#C. Difficile\n",
    "Difficile=data.loc[(data['DIAG_DESC']=='C. Difficile')]\n",
    "Difficile_counts=Difficile['SUBJ_ID'].value_counts()\n",
    "\n",
    "Difficile_entered_2=Difficile[Difficile['SUBJ_ID'].isin(Difficile_counts.index[(Difficile_counts ==2)])]    \n",
    "Difficile_entered_2['Change']=Difficile_entered_2.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "\n",
    "\n",
    "for e in (Difficile_entered_2.loc[(Difficile_entered_2['Change']< 31)])['SUBJ_ID'].unique().tolist():\n",
    "    Difficile_entered_2.drop(Difficile_entered_2.loc[(Difficile_entered_2['SUBJ_ID']==e)&(Difficile_entered_2['Change'].isnull())].index, inplace=True)\n",
    "\n",
    "    \n",
    "Difficile_entered_3=Difficile[Difficile['SUBJ_ID'].isin(Difficile_counts.index[(Difficile_counts >2)])] \n",
    "Difficile_entered_3['Change']=Difficile_entered_3.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "\n",
    "Difficile_entered_3.drop(Difficile_entered_3.loc[(Difficile_entered_3['SUBJ_ID']=='410')&(Difficile_entered_3['Days_to_Diag']==727)].index, inplace=True)\n",
    "Difficile_entered_3.drop(Difficile_entered_3.loc[(Difficile_entered_3['SUBJ_ID']=='1356')&(Difficile_entered_3['Days_to_Diag']==4655)].index, inplace=True)\n",
    "Difficile_entered_3.drop(Difficile_entered_3.loc[(Difficile_entered_3['SUBJ_ID']=='1409')&(Difficile_entered_3['Days_to_Diag']==1392)].index, inplace=True)\n",
    "Difficile_entered_3.drop(Difficile_entered_3.loc[(Difficile_entered_3['SUBJ_ID']=='3319')&(Difficile_entered_3['Days_to_Diag']==213)].index, inplace=True)\n",
    "\n",
    "#Pneumonia entered three is the database where Pneumonia is diagnosed 3 time:\n",
    "Difficile_entered_1=Difficile[Difficile['SUBJ_ID'].isin(Difficile_counts.index[(Difficile_counts==1)])]    \n",
    "\n",
    "Difficile_frames = [Difficile_entered_1, Difficile_entered_2, Difficile_entered_3]\n",
    "Difficile_database = pd.concat(Difficile_frames)\n",
    "\n",
    "#Cholangitis\n",
    "Cholangitis=data.loc[(data['DIAG_DESC']=='Cholangitis')]\n",
    "Cholangitis_counts=Cholangitis['SUBJ_ID'].value_counts()\n",
    "\n",
    "Cholangitis_entered_2=Cholangitis[Cholangitis['SUBJ_ID'].isin(Cholangitis_counts.index[(Cholangitis_counts ==2)])]\n",
    "\n",
    "Cholangitis_entered_2['Change']=Cholangitis_entered_2.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "\n",
    "\n",
    "for e in (Cholangitis_entered_2.loc[(Cholangitis_entered_2['Change']< 31)])['SUBJ_ID'].unique().tolist():\n",
    "    Cholangitis_entered_2.drop(Cholangitis_entered_2.loc[(Cholangitis_entered_2['SUBJ_ID']==e)&(Cholangitis_entered_2['Change'].isnull())].index, inplace=True)\n",
    "\n",
    "\n",
    "Cholangitis_entered_3=Cholangitis[Cholangitis['SUBJ_ID'].isin(Cholangitis_counts.index[(Cholangitis_counts >2)])]\n",
    "\n",
    "Cholangitis_entered_3['Change']=Cholangitis_entered_3.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "\n",
    "\n",
    "Cholangitis_entered_3.drop(Cholangitis_entered_3.loc[(Cholangitis_entered_3['SUBJ_ID']=='604')&(Cholangitis_entered_3['Days_to_Diag']==1887)].index, inplace=True)\n",
    "Cholangitis_entered_3.drop(Cholangitis_entered_3.loc[(Cholangitis_entered_3['SUBJ_ID']=='847')&(Cholangitis_entered_3['Days_to_Diag']==3247)].index, inplace=True)\n",
    "Cholangitis_entered_3.drop(Cholangitis_entered_3.loc[(Cholangitis_entered_3['SUBJ_ID']=='938')&(Cholangitis_entered_3['Days_to_Diag']==877)].index, inplace=True)\n",
    "Cholangitis_entered_3.drop(Cholangitis_entered_3.loc[(Cholangitis_entered_3['SUBJ_ID']=='938')&(Cholangitis_entered_3['Days_to_Diag']==1325)].index, inplace=True)\n",
    "Cholangitis_entered_3.drop(Cholangitis_entered_3.loc[(Cholangitis_entered_3['SUBJ_ID']=='1253')&(Cholangitis_entered_3['Days_to_Diag']==1282)].index, inplace=True)\n",
    "\n",
    "\n",
    "Cholangitis_entered_1=Cholangitis[Cholangitis['SUBJ_ID'].isin(Cholangitis_counts.index[(Cholangitis_counts ==1)])]\n",
    "\n",
    "\n",
    "Cholangitis_frames = [Cholangitis_entered_1, Cholangitis_entered_2, Cholangitis_entered_3]\n",
    "\n",
    "Cholangitis_database = pd.concat(Cholangitis_frames)\n",
    "\n",
    "\n",
    "#CMV\n",
    "CMV=data.loc[(data['DIAG_DESC']=='CMV')]\n",
    "CMV_counts=CMV['SUBJ_ID'].value_counts()\n",
    "CMV_entered_2=CMV[CMV['SUBJ_ID'].isin(CMV_counts.index[(CMV_counts ==2)])]\n",
    "CMV_entered_2['Change']=CMV_entered_2.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "\n",
    "for e in (CMV_entered_2.loc[(CMV_entered_2['Change']< 31)])['SUBJ_ID'].unique().tolist():\n",
    "    CMV_entered_2.drop(CMV_entered_2.loc[(CMV_entered_2['SUBJ_ID']==e)&(CMV_entered_2['Change'].isnull())].index, inplace=True)\n",
    "\n",
    "\n",
    "CMV_entered_3=CMV[CMV['SUBJ_ID'].isin(CMV_counts.index[(CMV_counts >2)])]\n",
    "\n",
    "CMV_entered_3['Change']=CMV_entered_3.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "CMV_entered_3.drop(CMV_entered_3.loc[(CMV_entered_3['SUBJ_ID']=='244')&(CMV_entered_3['Days_to_Diag']==11)].index, inplace=True)\n",
    "CMV_entered_3.drop(CMV_entered_3.loc[(CMV_entered_3['SUBJ_ID']=='666')&(CMV_entered_3['Days_to_Diag']==187)].index, inplace=True)\n",
    "CMV_entered_3.drop(CMV_entered_3.loc[(CMV_entered_3['SUBJ_ID']=='1171')&(CMV_entered_3['Days_to_Diag']==95)].index, inplace=True)\n",
    "CMV_entered_3.drop(CMV_entered_3.loc[(CMV_entered_3['SUBJ_ID']=='1409')&(CMV_entered_3['Days_to_Diag']==137)].index, inplace=True)\n",
    "CMV_entered_3.drop(CMV_entered_3.loc[(CMV_entered_3['SUBJ_ID']=='1895')&(CMV_entered_3['Days_to_Diag']==263)].index, inplace=True)\n",
    "CMV_entered_3.drop(CMV_entered_3.loc[(CMV_entered_3['SUBJ_ID']=='2311')&(CMV_entered_3['Days_to_Diag']==2)].index, inplace=True)\n",
    "CMV_entered_3.drop(CMV_entered_3.loc[(CMV_entered_3['SUBJ_ID']=='2907')&(CMV_entered_3['Days_to_Diag']==139)&(CMV_entered_3['Change']==0.0)].index, inplace=True)\n",
    "CMV_entered_3.drop(CMV_entered_3.loc[(CMV_entered_3['SUBJ_ID']=='3011')&(CMV_entered_3['Days_to_Diag']==139)&(CMV_entered_3['Change']==0.0)].index, inplace=True)\n",
    "CMV_entered_3.drop(CMV_entered_3.loc[(CMV_entered_3['SUBJ_ID']=='3500')&(CMV_entered_3['Days_to_Diag']==57)].index, inplace=True)\n",
    "\n",
    "CMV_entered_1=CMV[CMV['SUBJ_ID'].isin(CMV_counts.index[(CMV_counts==1)])]\n",
    "\n",
    "CMV_frames = [CMV_entered_1, CMV_entered_2, CMV_entered_3]\n",
    "\n",
    "CMV_database = pd.concat(CMV_frames)\n",
    "\n",
    "\n",
    "##UTI\n",
    "UTI=data.loc[(data['DIAG_DESC']=='UTI')]\n",
    "UTI_counts=UTI['SUBJ_ID'].value_counts()\n",
    "UTI_entered_2=UTI[UTI['SUBJ_ID'].isin(UTI_counts.index[(UTI_counts ==2)])]\n",
    "UTI_entered_2['Change']=UTI_entered_2.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "\n",
    "for e in (UTI_entered_2.loc[(UTI_entered_2['Change']< 31)])['SUBJ_ID'].unique().tolist():\n",
    "    UTI_entered_2.drop(UTI_entered_2.loc[(UTI_entered_2['SUBJ_ID']==e)&(UTI_entered_2['Change'].isnull())].index, inplace=True)\n",
    "\n",
    "\n",
    "UTI_entered_3=UTI[UTI['SUBJ_ID'].isin(UTI_counts.index[(UTI_counts >2)])]\n",
    "UTI_entered_3['Change']=UTI_entered_3.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "UTI_entered_3.drop(UTI_entered_3.loc[(UTI_entered_3['SUBJ_ID']=='85')&(UTI_entered_3['Days_to_Diag']==121)].index, inplace=True)\n",
    "UTI_entered_3.drop(UTI_entered_3.loc[(UTI_entered_3['SUBJ_ID']=='531')&(UTI_entered_3['Days_to_Diag']==7848)].index, inplace=True)\n",
    "UTI_entered_3.drop(UTI_entered_3.loc[(UTI_entered_3['SUBJ_ID']=='633')&(UTI_entered_3['Days_to_Diag']==30)].index, inplace=True)\n",
    "UTI_entered_3.drop(UTI_entered_3.loc[(UTI_entered_3['SUBJ_ID']=='1076')&(UTI_entered_3['Days_to_Diag']==82)].index, inplace=True)\n",
    "UTI_entered_3.drop(UTI_entered_3.loc[(UTI_entered_3['SUBJ_ID']=='1076')&(UTI_entered_3['Days_to_Diag']==43)].index, inplace=True)\n",
    "UTI_entered_3.drop(UTI_entered_3.loc[(UTI_entered_3['SUBJ_ID']=='1356')&(UTI_entered_3['Days_to_Diag']==2882)].index, inplace=True)\n",
    "UTI_entered_3.drop(UTI_entered_3.loc[(UTI_entered_3['SUBJ_ID']=='2815')&(UTI_entered_3['Days_to_Diag']==35)].index, inplace=True)\n",
    "UTI_entered_3.drop(UTI_entered_3.loc[(UTI_entered_3['SUBJ_ID']=='2815')&(UTI_entered_3['Days_to_Diag']==28)].index, inplace=True)\n",
    "UTI_entered_3.drop(UTI_entered_3.loc[(UTI_entered_3['SUBJ_ID']=='3133')&(UTI_entered_3['Days_to_Diag']==901)].index, inplace=True)\n",
    "UTI_entered_3.drop(UTI_entered_3.loc[(UTI_entered_3['SUBJ_ID']=='3469')&(UTI_entered_3['Days_to_Diag']>7)].index, inplace=True)\n",
    "UTI_entered_3.drop(UTI_entered_3.loc[(UTI_entered_3['SUBJ_ID']=='3526')&(UTI_entered_3['Days_to_Diag']>9)].index, inplace=True)\n",
    "\n",
    "\n",
    "UTI_entered_1=UTI[UTI['SUBJ_ID'].isin(UTI_counts.index[(UTI_counts ==1)])]\n",
    "UTI_frames = [UTI_entered_1, UTI_entered_2, UTI_entered_3]\n",
    "\n",
    "UTI_database = pd.concat(UTI_frames)\n",
    "\n",
    "\n",
    "#Rejection\n",
    "Rejection=data.loc[(data['DIAG_DESC']=='Rejection')]\n",
    "Rejection_counts=Rejection['SUBJ_ID'].value_counts()\n",
    "\n",
    "Rejection_entered_2=Rejection[Rejection['SUBJ_ID'].isin(Rejection_counts.index[(Rejection_counts ==2)])]\n",
    "Rejection_entered_2['Change']=Rejection_entered_2.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "\n",
    "for e in (Rejection_entered_2.loc[(Rejection_entered_2['Change']< 31)])['SUBJ_ID'].unique().tolist():\n",
    "    Rejection_entered_2.drop(Rejection_entered_2.loc[(Rejection_entered_2['SUBJ_ID']==e)&(Rejection_entered_2['Change'].isnull())].index, inplace=True)\n",
    "\n",
    "\n",
    "Rejection_entered_3=Rejection[Rejection['SUBJ_ID'].isin(Rejection_counts.index[(Rejection_counts >2)])]\n",
    "Rejection_entered_3['Change']=Rejection_entered_3.groupby('SUBJ_ID')['Days_to_Diag'].apply(lambda x: x.shift() - x)\n",
    "\n",
    "Rejection_entered_1=Rejection[Rejection['SUBJ_ID'].isin(Rejection_counts.index[(Rejection_counts ==1)])]\n",
    "\n",
    "Rejection_frames = [Rejection_entered_1, Rejection_entered_2, Rejection_entered_3]\n",
    "Rejection_database = pd.concat(Rejection_frames)\n",
    "\n",
    "#final_frames=[]\n",
    "final_frames=[Osteoporosispenia_database,Denovo_Malignancy_database,Renal_dysfunction_database,Liver_Fibrosis_database,Smoking_database,Esophageal_Varices_database,HCC_database,Pleural_Effusion_database,Atrial_database,Ascites_database,Diabetes_database,Hypertension_database,cirrhosis_database,PTC_database,Shingles_database,NAFLD_database,Overweight_database,Duct_database,sepsis_database,Pneumonia_database,Difficile_database,Cholangitis_database,CMV_database,UTI_database,Rejection_database]\n",
    "final_database=pd.concat(final_frames)\n",
    "final_database=final_database.drop(['Change'], axis=1)\n",
    "\n",
    "final_database=final_database.drop_duplicates()\n",
    "final_database=final_database.sort_values(by=['SUBJ_ID','Days_to_Diag'])\n",
    "final_database.to_excel('UHN_DIAG.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_list=['Sepsis', 'Pneumonia', 'C. Difficile', 'Cholangitis', 'CMV','UTI','Rejection']\n",
    "\n",
    "data.loc[(data['DIAG_DESC']=='CMV','CMV_Diag')]=1\n",
    "\n",
    "data.loc[(data['DIAG_DESC']=='Sepsis','Sepsis_Diag')]=1\n",
    "\n",
    "data.loc[(data['DIAG_DESC']=='C. Difficile','C. Difficile_Diag')]=1\n",
    "\n",
    "data.loc[(data['DIAG_DESC']=='Cholangitis','Cholangitis_Diag')]=1\n",
    "\n",
    "#data.loc[(data['DIAG_DESC']=='CMV','Pneumonia_Diag')]=1\n",
    "\n",
    "data.loc[(data['DIAG_DESC']=='UTI','UTI_Diag')]=1\n",
    "\n",
    "data.loc[(data['DIAG_DESC']=='Rejection','Rejection_Diag')]=1\n",
    "\n",
    "data.loc[(data['DIAG_DESC']=='Pneumonia','Pneumonia_Diag')]=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('UHN_DIAG.xlsx')\n",
    "bw_panel=pd.read_excel('Processed_bw_panel.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Osteoporosis/penia\n",
    "Osteoporosis_ID=data.loc[data['DIAG_DESC']=='Osteoporosis/penia','SUBJ_ID'].tolist()\n",
    "\n",
    "Osteoporosis_date=data.loc[data['DIAG_DESC']=='Osteoporosis/penia','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(Osteoporosis_ID,Osteoporosis_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Osteoporosis/penia')]=1.0\n",
    " \n",
    "\n",
    "#Renal dysfunction\n",
    "Renal_ID=data.loc[data['DIAG_DESC']=='Renal dysfunction','SUBJ_ID'].tolist()\n",
    "\n",
    "Renal_date=data.loc[data['DIAG_DESC']=='Renal dysfunction','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(Renal_ID,Renal_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Renal dysfunction')]=1.0\n",
    "\n",
    "\n",
    "    \n",
    "#Atrial Fibrillation:\n",
    "Atrial_ID=data.loc[data['DIAG_DESC']=='Atrial Fibrillation','SUBJ_ID'].tolist()\n",
    "\n",
    "Atrial_date=data.loc[data['DIAG_DESC']=='Atrial Fibrillation','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(Atrial_ID,Atrial_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Atrial Fibrillation')]=1.0\n",
    "\n",
    "\n",
    "#Diabetes:\n",
    "Diabetes_ID=data.loc[data['DIAG_DESC']=='Diabetes','SUBJ_ID'].tolist()\n",
    "\n",
    "Diabetes_date=data.loc[data['DIAG_DESC']=='Diabetes','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(Diabetes_ID,Diabetes_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Diabetes')]=1.0\n",
    "\n",
    "    \n",
    "#Denovo Malignancy:\n",
    "Malig_ID=data.loc[data['DIAG_DESC']=='Denovo Malignancy','SUBJ_ID'].tolist()\n",
    "\n",
    "Malig_date=data.loc[data['DIAG_DESC']=='Denovo Malignancy','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(Malig_ID,Malig_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Denovo Malignancy')]=1.0\n",
    "\n",
    "#Billiary Duct Issues\n",
    "\n",
    "Duct_ID=data.loc[data['DIAG_DESC']=='Billiary Duct Issues','SUBJ_ID'].tolist()\n",
    "\n",
    "Duct_date=data.loc[data['DIAG_DESC']=='Billiary Duct Issues','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(Duct_ID,Duct_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Billiary Duct Issues')]=1.0\n",
    "\n",
    "    \n",
    "#graft cirrhosis:\n",
    "cirrhosis_ID=data.loc[data['DIAG_DESC']=='graft cirrhosis','SUBJ_ID'].tolist()\n",
    "\n",
    "cirrhosis_date=data.loc[data['DIAG_DESC']=='graft cirrhosis','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(cirrhosis_ID,cirrhosis_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'graft cirrhosis')]=1.0\n",
    "\n",
    "    \n",
    "#Pleural Effusion:\n",
    "Effusion_ID=data.loc[data['DIAG_DESC']=='Pleural Effusion','SUBJ_ID'].tolist()\n",
    "\n",
    "Effusion_date=data.loc[data['DIAG_DESC']=='Pleural Effusion','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(Effusion_ID,Effusion_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Pleural Effusion')]=1.0\n",
    "    \n",
    "    \n",
    "#Ascites\n",
    "Ascites_ID=data.loc[data['DIAG_DESC']=='Ascites','SUBJ_ID'].tolist()\n",
    "\n",
    "Ascites_date=data.loc[data['DIAG_DESC']=='Ascites','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(Ascites_ID,Ascites_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Ascites')]=1.0\n",
    "\n",
    "#Liver Fibrosis:\n",
    "Fibrosis_ID=data.loc[data['DIAG_DESC']=='Liver Fibrosis','SUBJ_ID'].tolist()\n",
    "\n",
    "Fibrosis_date=data.loc[data['DIAG_DESC']=='Liver Fibrosis','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(Fibrosis_ID,Fibrosis_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Liver Fibrosis')]=1.0\n",
    "    \n",
    "\n",
    "#NAFLD:\n",
    "NAFLD_ID=data.loc[data['DIAG_DESC']=='NAFLD','SUBJ_ID'].tolist()\n",
    "\n",
    "NAFLD_date=data.loc[data['DIAG_DESC']=='NAFLD','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(NAFLD_ID,NAFLD_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'NAFLD')]=1.0\n",
    "    \n",
    "\n",
    "    \n",
    "#History of Smoking:\n",
    "Smoking_ID=data.loc[data['DIAG_DESC']=='History of Smoking','SUBJ_ID'].tolist()\n",
    "\n",
    "Smoking_date=data.loc[data['DIAG_DESC']=='History of Smoking','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(Smoking_ID,Smoking_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'History of Smoking')]=1.0\n",
    "    \n",
    "\n",
    "    \n",
    "#PTC drain issue:\n",
    "PTC_ID=data.loc[data['DIAG_DESC']=='PTC drain issue','SUBJ_ID'].tolist()\n",
    "\n",
    "PTC_date=data.loc[data['DIAG_DESC']=='PTC drain issue','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(PTC_ID,PTC_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'PTC drain issue')]=1.0\n",
    "    \n",
    "    \n",
    "\n",
    "#Recurrent HCC:\n",
    "HCC_ID=data.loc[data['DIAG_DESC']=='Recurrent HCC','SUBJ_ID'].tolist()\n",
    "\n",
    "HCC_date=data.loc[data['DIAG_DESC']=='Recurrent HCC','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(HCC_ID,HCC_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Recurrent HCC')]=1.0\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "#Systematic Hypertension:\n",
    "hyper_ID=data.loc[data['DIAG_DESC']=='Systematic Hypertension','SUBJ_ID'].tolist()\n",
    "\n",
    "hyper_date=data.loc[data['DIAG_DESC']=='Systematic Hypertension','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(hyper_ID,hyper_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Systematic Hypertension')]=1.0\n",
    "    \n",
    "\n",
    "    \n",
    "#Shingles:\n",
    "Shingles_ID=data.loc[data['DIAG_DESC']=='Shingles','SUBJ_ID'].tolist()\n",
    "\n",
    "Shingles_date=data.loc[data['DIAG_DESC']=='Shingles','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(Shingles_ID,Shingles_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Shingles')]=1.0\n",
    "    \n",
    "\n",
    "#Esophageal Varices:\n",
    "Eso_ID=data.loc[data['DIAG_DESC']=='Esophageal Varices','SUBJ_ID'].tolist()\n",
    "\n",
    "Eso_date=data.loc[data['DIAG_DESC']=='Esophageal Varices','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(Eso_ID,Eso_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Esophageal Varices')]=1.0\n",
    "    \n",
    "\n",
    "#Overweight:\n",
    "Overweight_ID=data.loc[data['DIAG_DESC']=='Overweight','SUBJ_ID'].tolist()\n",
    "\n",
    "Overweight_date=data.loc[data['DIAG_DESC']=='Overweight','Days_to_Diag'].tolist()\n",
    "\n",
    "for x,y in zip(Overweight_ID,Overweight_date):\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==x)&(bw_panel['days_from_tx']>=y)),'Overweight')]=1.0\n",
    "\n",
    "data['DIAG_DESC'].unique()\n",
    "desired_list=['Sepsis', 'Pneumonia', 'C. Difficile', 'Cholangitis', 'CMV','UTI','Rejection']\n",
    "\n",
    "other_variables=[e for e in data['DIAG_DESC'].unique().tolist() if e not in desired_list]\n",
    "    \n",
    "\n",
    "sepsis=data.loc[data['DIAG_DESC']=='Sepsis',['SUBJ_ID','Days_to_Diag']]\n",
    "sepsis['SUBJ_ID']\n",
    "idx = np.arange(1,245,1)\n",
    "sepsis.index = idx\n",
    "\n",
    "for i in sepsis.index:\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==sepsis['SUBJ_ID'][i])&(bw_panel['days_from_tx']==sepsis['Days_to_Diag'][i])),'Sepsis')]=1.0\n",
    "    \n",
    "Pneumonia=data.loc[data['DIAG_DESC']=='Pneumonia',['SUBJ_ID','Days_to_Diag']]\n",
    "Pneumonia_idx = np.arange(1,355,1)\n",
    "Pneumonia.index = Pneumonia_idx\n",
    "\n",
    "for i in Pneumonia.index:\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==Pneumonia['SUBJ_ID'][i])&(bw_panel['days_from_tx']==Pneumonia['Days_to_Diag'][i])),'Pneumonia')]=1.0\n",
    "  \n",
    "#C. Difficile\n",
    "Difficile=data.loc[data['DIAG_DESC']=='C. Difficile',['SUBJ_ID','Days_to_Diag']]\n",
    "Difficile_idx = np.arange(1,200,1)\n",
    "Difficile.index = Difficile_idx\n",
    "\n",
    "for i in Difficile.index:\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==Difficile['SUBJ_ID'][i])&(bw_panel['days_from_tx']==Difficile['Days_to_Diag'][i])),'C. Difficile')]=1.0\n",
    "  \n",
    "#Cholangitis\n",
    "\n",
    "Cholangitis=data.loc[data['DIAG_DESC']=='Cholangitis',['SUBJ_ID','Days_to_Diag']]\n",
    "Cholangitis_idx = np.arange(1,201,1)\n",
    "Cholangitis.index = Cholangitis_idx\n",
    "\n",
    "for i in Difficile.index:\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==Cholangitis['SUBJ_ID'][i])&(bw_panel['days_from_tx']==Cholangitis['Days_to_Diag'][i])),'Cholangitis')]=1.0\n",
    "  \n",
    "\n",
    "#CMV\n",
    "CMV=data.loc[data['DIAG_DESC']=='CMV',['SUBJ_ID','Days_to_Diag']]\n",
    "CMV_idx = np.arange(1,451,1)\n",
    "CMV.index = CMV_idx\n",
    "\n",
    "for i in CMV.index:\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==CMV['SUBJ_ID'][i])&(bw_panel['days_from_tx']==CMV['Days_to_Diag'][i])),'CMV')]=1.0\n",
    "  \n",
    "\n",
    "#UTI:\n",
    "UTI=data.loc[data['DIAG_DESC']=='UTI',['SUBJ_ID','Days_to_Diag']]\n",
    "UTI_idx = np.arange(1,465,1)\n",
    "UTI.index = UTI_idx\n",
    "\n",
    "for i in UTI.index:\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==UTI['SUBJ_ID'][i])&(bw_panel['days_from_tx']==UTI['Days_to_Diag'][i])),'UTI')]=1.0\n",
    "  \n",
    "#Rejection:\n",
    "Rejection=data.loc[data['DIAG_DESC']=='Rejection',['SUBJ_ID','Days_to_Diag']]\n",
    "Rejection_idx = np.arange(1,1049,1)\n",
    "Rejection.index = Rejection_idx\n",
    "\n",
    "for i in Rejection.index:\n",
    "    bw_panel.loc[(((bw_panel['SUBJECT_ID']==Rejection['SUBJ_ID'][i])&(bw_panel['days_from_tx']==Rejection['Days_to_Diag'][i])),'Rejection')]=1.0\n",
    "  \n",
    "Columns=data['DIAG_DESC'].unique().tolist()\n",
    "for e in Columns:\n",
    "    bw_panel[e]=bw_panel[e].replace(np.NaN,0.0)\n",
    "    \n",
    "bw_panel.to_excel('UHN_bw_panel.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
